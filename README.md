# ğŸ§  Non-Linear Agent Using LangGraph + Mistral via Ollama

A smart, dynamic AI agent built using [LangGraph](https://github.com/langchain-ai/langgraph), powered by [Mistral LLM](https://mistral.ai) and served locally via [Ollama](https://ollama.com). This agent leverages a **non-linear execution graph** to perform advanced multi-step reasoning, tool usage, and memory-based decision-making.

---

## ğŸš€ Project Overview

Traditional agents follow a linear sequence of steps. In contrast, this project demonstrates a **non-linear agent architecture** using **LangGraph**, enabling:

- Branching decisions based on output
- Tool invocation logic
- Stateful memory handling
- Looping, conditional execution, and complex flow

All powered by the **Mistral** language model hosted locally with **Ollama**.

---

## ğŸ› ï¸ Tech Stack

| Layer          | Technology         |
|----------------|--------------------|
| Language Model | [Mistral](https://mistral.ai) via [Ollama](https://ollama.com) |
| Graph Engine   | [LangGraph](https://github.com/langchain-ai/langgraph) |
| Agent Framework| [LangChain](https://www.langchain.com) |
| Programming    | Python |
| Tools          | Built-in LangChain tools or custom tools (e.g., Math, Search, Python REPL) |

---

## ğŸ“Œ Features

- ğŸ§­ **Non-linear Agent Routing** using LangGraph nodes
- ğŸ§  **LLM-Driven Decisions** powered by Mistral
- ğŸ” **Conditional Loops and Memory** (Conversation history, results caching)
- ğŸ§° **Tool Calling Support** (e.g., Search, Calculator, Python REPL)
- âš¡ **Runs Fully Local** with Ollama + Mistral
- ğŸ§ª **Extendable**: Add custom tools, memory modules, and branches

---

## ğŸ“‚ Project Structure

```bash
nonlinear-agent/
â”‚
â”œâ”€â”€ main.py                # Entry point
â”œâ”€â”€ agent_graph.py         # LangGraph flow definition
â”œâ”€â”€ tools.py               # Custom and built-in tool definitions
â”œâ”€â”€ memory.py              # Optional: memory integration
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md              # This file
â””â”€â”€ .env                   # Optional: env vars (API keys, etc.)


ğŸ”§ Setup Instructions
1. Install Ollama & Pull Mistral
curl -fsSL https://ollama.com/install.sh | sh
ollama run mistral

2. Clone the Repository
git clone https://github.com/yourusername/nonlinear-agent.git
cd nonlinear-agent


3. Create Virtual Environment & Install Requirements
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt


4. Run the Agent
python main.py


ğŸ¤– Architecture Diagram
[User Input]
     â†“
[LangGraph Node: Input Handler]
     â†“
[LangGraph Node: Decide â†’ Tool? â†’ Memory? â†’ End?]
     â†™         â†“        â†˜
[Tool Node] [Memory Node] [Final Output]
     â†“         â†“            â†‘
    Loop back to decision if needed


ğŸŒ References
LangGraph Documentation
Ollama + Mistral Setup
LangChain Agents

ğŸ™‹â€â™‚ï¸ Author
Made by Shaik Nazeer
